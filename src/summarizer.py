import re
import orjson as json
from datetime import datetime
from zoneinfo import ZoneInfo
from contextlib import closing
from html import escape

import google.generativeai as genai
import tiktoken
from openai import AsyncOpenAI

from telegram import Chat
from telegram.ext import ContextTypes

import src.config as config
from src.db import db
from src.utils import utc_ts, clean_text, message_link, user_link

genai.configure(api_key=config.GEMINI_API_KEY)
gemini_model = genai.GenerativeModel(
    config.GEMINI_MODEL_NAME,
    generation_config={"response_mime_type": "application/json"}
)
openai_client = AsyncOpenAI(api_key=config.OPENAI_API_KEY)

MAX_TOPICS_NUM = 7


def get_toxicity_prompt(toxicity_level: int) -> str:
    """Generate prompt based on toxicity level (0-9)"""

    base_prompt = f"""–¢–∏ ‚Äî –ø–æ–º—ñ—á–Ω–∏–∫, —â–æ –≥—Ä—É–ø—É—î –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è —á–∞—Ç—É —É —Ç–µ–º–∏ –∑–∞ –∫–∞–ª–µ–Ω–¥–∞—Ä–Ω–∏–π –¥–µ–Ω—å.

–ó–∞–≤–¥–∞–Ω–Ω—è:
1) –ó–∫–ª–∞—Å—Ç–µ—Ä–∏–∑—É–π –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è —É 2‚Äì{MAX_TOPICS_NUM} —Ç–µ–º.
2) –î–ª—è –∫–æ–∂–Ω–æ—ó —Ç–µ–º–∏ –≤–∏–∑–Ω–∞—á:
   - short_title: ‚â§7 —Å–ª—ñ–≤, –∑–º—ñ—Å—Ç–æ–≤–Ω–∞ –Ω–∞–∑–≤–∞
   - first_message_id: message_id –ø–µ—Ä—à–æ–≥–æ (–Ω–∞–π—Ä–∞–Ω—ñ—à–æ–≥–æ) –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è –≤ —Ç–µ–º—ñ
   - initiator_user_id: user_id –∞–≤—Ç–æ—Ä–∞ –ø–µ—Ä—à–æ–≥–æ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è —Ç–µ–º–∏
   - summary: 1‚Äì3 —Ä–µ—á–µ–Ω–Ω—è –ø—ñ–¥—Å—É–º–∫—É –∑ –∫–æ–º–µ–Ω—Ç–∞—Ä–µ–º —É –≤—ñ–¥–ø–æ–≤—ñ–¥–Ω–æ–º—É —Å—Ç–∏–ª—ñ.

3) –ü–æ–≤–µ—Ä–Ω–∏ –†–Ü–í–ù–û JSON —Ç–∞–∫–æ–≥–æ –≤–∏–≥–ª—è–¥—É:
{{
  "topics": [
    {{
      "short_title": "‚Ä¶",
      "first_message_id": 123,
      "initiator_user_id": 456,
      "summary": "‚Ä¶"
    }}
  ]
}}

–£–í–ê–ì–ê:
- –û—Ä—ñ—î–Ω—Ç—É–π—Å—è –Ω–∞ reply-–ª–∞–Ω—Ü—é–∂–∫–∏ —è–∫ –æ–∑–Ω–∞–∫—É —Ç–µ–º–∏; –¥–ª—è –Ω–µ—Ä–µ–ø–ª–∞–π–Ω–∏—Ö ‚Äî –æ–±'—î–¥–Ω—É–π –∑–∞ –∑–º—ñ—Å—Ç–æ–º.
- –Ü–≥–Ω–æ—Ä—É–π —Å–ª—É–∂–±–æ–≤—ñ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è/—Å—Ç—ñ–∫–µ—Ä–∏, —è–∫—â–æ –≤–æ–Ω–∏ –Ω—ñ—á–æ–≥–æ –Ω–µ –¥–æ–¥–∞—é—Ç—å –ø–æ —Å—É—Ç—ñ.
"""

    toxicity_styles = {
        0: """
–°–¢–ò–õ–¨–û–í–Ü –í–ò–ú–û–ì–ò:
- –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π –¥—Ä—É–∂–µ–ª—é–±–Ω–∏–π —Ç–∞ –ø–æ–∑–∏—Ç–∏–≤–Ω–∏–π —Ç–æ–Ω
- –ë—É–¥—å –ø—ñ–¥—Ç—Ä–∏–º—É—é—á–∏–º —Ç–∞ –∫–æ–Ω—Å—Ç—Ä—É–∫—Ç–∏–≤–Ω–∏–º
- –ó–Ω–∞—Ö–æ–¥—å –ø–æ–∑–∏—Ç–∏–≤–Ω—ñ –º–æ–º–µ–Ω—Ç–∏ –≤ –æ–±–≥–æ–≤–æ—Ä–µ–Ω–Ω—è—Ö
- –î–ª—è —Ä–æ—Å—ñ–π—Å—å–∫–∏—Ö —Ç–µ–º - –Ω–µ–π—Ç—Ä–∞–ª—å–Ω–∏–π –æ–ø–∏—Å –±–µ–∑ –µ–º–æ—Ü—ñ–π
- –£–Ω–∏–∫–∞–π –±—É–¥—å-—è–∫–æ—ó –∫—Ä–∏—Ç–∏–∫–∏ –∞–±–æ –Ω–µ–≥–∞—Ç–∏–≤—É
""",
        1: """
–°–¢–ò–õ–¨–û–í–Ü –í–ò–ú–û–ì–ò:
- –õ–µ–≥–∫–∏–π –≥—É–º–æ—Ä –±–µ–∑ –æ–±—Ä–∞–∑
- –ú'—è–∫–∏–π —Ç–∞ –¥—Ä—É–∂–µ–ª—é–±–Ω–∏–π —Ç–æ–Ω
- –ù–µ–≤–µ–ª–∏–∫—ñ –∂–∞—Ä—Ç—ñ–≤–ª–∏–≤—ñ –∫–æ–º–µ–Ω—Ç–∞—Ä—ñ
- –î–ª—è —Ä–æ—Å—ñ–π—Å—å–∫–∏—Ö —Ç–µ–º - —Å—Ç—Ä–∏–º–∞–Ω–∏–π –æ–ø–∏—Å
- –ü–æ–∑–∏—Ç–∏–≤–Ω–∏–π –Ω–∞—Å—Ç—Ä—ñ–π
""",
        2: """
–°–¢–ò–õ–¨–û–í–Ü –í–ò–ú–û–ì–ò:
- –ü–æ–º—ñ—Ä–Ω–∏–π –≥—É–º–æ—Ä —Ç–∞ —ñ—Ä–æ–Ω—ñ—è
- –õ–µ–≥–∫–∞ –∫—Ä–∏—Ç–∏–∫–∞ –±–µ–∑ –∞–≥—Ä–µ—Å—ñ—ó
- –ñ–∞—Ä—Ç—ñ–≤–ª–∏–≤—ñ –∑–∞—É–≤–∞–∂–µ–Ω–Ω—è
- –î–ª—è —Ä–æ—Å—ñ–π—Å—å–∫–∏—Ö —Ç–µ–º - –ª–µ–≥–∫–∞ –∫—Ä–∏—Ç–∏–∫–∞
- –î—Ä—É–∂–µ–ª—é–±–Ω–∞ –∞—Ç–º–æ—Å—Ñ–µ—Ä–∞
""",
        3: """
–°–¢–ò–õ–¨–û–í–Ü –í–ò–ú–û–ì–ò:
- –Ü—Ä–æ–Ω—ñ—è —Ç–∞ —Å–∞—Ä–∫–∞–∑–º —É –ø–æ–º—ñ—Ä–Ω–∏—Ö –¥–æ–∑–∞—Ö
- –ú'—è–∫–∞ –∫—Ä–∏—Ç–∏–∫–∞ –¥—É—Ä–Ω–∏—Ü—å
- –ñ–∞—Ä—Ç—ñ–≤–ª–∏–≤–µ –≤–∏—Å–º—ñ—é–≤–∞–Ω–Ω—è
- –î–ª—è —Ä–æ—Å—ñ–π—Å—å–∫–∏—Ö —Ç–µ–º - –∫—Ä–∏—Ç–∏—á–Ω—ñ –∑–∞—É–≤–∞–∂–µ–Ω–Ω—è
- –ë–∞–ª–∞–Ω—Å –º—ñ–∂ –≥—É–º–æ—Ä–æ–º —Ç–∞ —Å–µ—Ä–π–æ–∑–Ω—ñ—Å—Ç—é
""",
        4: """
–°–¢–ò–õ–¨–û–í–Ü –í–ò–ú–û–ì–ò:
- –ü–æ–º—ñ—Ç–Ω–∏–π —Å–∞—Ä–∫–∞–∑–º —Ç–∞ —ñ—Ä–æ–Ω—ñ—è
- –ö—Ä–∏—Ç–∏–∫–∞ –≥–ª—É–ø–æ—Ç–∏ –±–µ–∑ –∂–æ—Ä—Å—Ç–æ–∫–æ—Å—Ç—ñ
- –î–æ—Å–∏—Ç—å —ó–¥–∫—ñ –∫–æ–º–µ–Ω—Ç–∞—Ä—ñ
- –î–ª—è —Ä–æ—Å—ñ–π—Å—å–∫–∏—Ö —Ç–µ–º - –Ω–µ–≥–∞—Ç–∏–≤–Ω–µ —Å—Ç–∞–≤–ª–µ–Ω–Ω—è
- –¢—Ä–æ—Ö–∏ –ø—Ä–æ–≤–æ–∫–∞—Ü—ñ–π–Ω–∏–π —Å—Ç–∏–ª—å
""",
        5: """
–°–¢–ò–õ–¨–û–í–Ü –í–ò–ú–û–ì–ò:
- –í–∏—Ä–∞–∂–µ–Ω–∏–π —Å–∞—Ä–∫–∞–∑–º —Ç–∞ —ó–¥–∫—ñ—Å—Ç—å
- –í—ñ–¥–≤–µ—Ä—Ç–∞ –∫—Ä–∏—Ç–∏–∫–∞ –¥—É—Ä–Ω–∏—Ü—å
- –ß–æ—Ä–Ω–∏–π –≥—É–º–æ—Ä —É –ø–æ–º—ñ—Ä–Ω–∏—Ö –¥–æ–∑–∞—Ö
- –î–ª—è —Ä–æ—Å—ñ–π—Å—å–∫–∏—Ö —Ç–µ–º - —Ä—ñ–∑–∫–∞ –∫—Ä–∏—Ç–∏–∫–∞ –æ–∫—É–ø–∞–Ω—Ç—ñ–≤
- –ü—Ä–æ–≤–æ–∫–∞—Ü—ñ–π–Ω—ñ –∫–æ–º–µ–Ω—Ç–∞—Ä—ñ
""",
        6: """
–°–¢–ò–õ–¨–û–í–Ü –í–ò–ú–û–ì–ò:
- –á–¥–∫–∏–π —Å–∞—Ä–∫–∞–∑–º —Ç–∞ —ñ—Ä–æ–Ω—ñ—è
- –ë–µ–∑–∂–∞–ª—ñ—Å–Ω–∞ –∫—Ä–∏—Ç–∏–∫–∞ –≥–ª—É–ø–æ—Ç–∏
- –ß–æ—Ä–Ω–∏–π –≥—É–º–æ—Ä
- –î–ª—è —Ä–æ—Å—ñ–π—Å—å–∫–∏—Ö —Ç–µ–º - –∂–æ—Ä—Å—Ç–∫–∞ –∫—Ä–∏—Ç–∏–∫–∞ —Ä–∞—à–∏—Å—Ç—ñ–≤
- –ö–æ–Ω—Ç—Ä–æ–≤–µ—Ä—Å—ñ–π–Ω—ñ –≤–∏—Å–ª–æ–≤–ª—é–≤–∞–Ω–Ω—è
""",
        7: """
–°–¢–ò–õ–¨–û–í–Ü –í–ò–ú–û–ì–ò:
- –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∏–π —Å–∞—Ä–∫–∞–∑–º —Ç–∞ —ó–¥–∫—ñ—Å—Ç—å
- –ù–µ—â–∞–¥–Ω–∞ –∫—Ä–∏—Ç–∏–∫–∞ —Ç—É–ø–æ—Å—Ç—ñ —Ç–∞ –ª–∏—Ü–µ–º—ñ—Ä—Å—Ç–≤–∞
- –ê–∫—Ç–∏–≤–Ω–∏–π —á–æ—Ä–Ω–∏–π –≥—É–º–æ—Ä
- –î–ª—è —Ä–æ—Å—ñ–π—Å—å–∫–∏—Ö —Ç–µ–º - —Å–ª–æ–≤–µ—Å–Ω–µ –∑–Ω–∏—â–µ–Ω–Ω—è –æ–∫—É–ø–∞–Ω—Ç—ñ–≤
- –î—É–∂–µ –ø—Ä–æ–≤–æ–∫–∞—Ü—ñ–π–Ω–∏–π —Å—Ç–∏–ª—å
""",
        8: """
–°–¢–ò–õ–¨–û–í–Ü –í–ò–ú–û–ì–ò:
- –í–∫—Ä–∞–π —Ç–æ–∫—Å–∏—á–Ω–∏–π —Å–∞—Ä–∫–∞–∑–º
- –ë–µ–∑–∂–∞–ª—ñ—Å–Ω–µ –≤–∏—Å–º—ñ—é–≤–∞–Ω–Ω—è –≤—Å—å–æ–≥–æ –±–µ–∑–≥–ª—É–∑–¥–æ–≥–æ
- –ñ–æ—Ä—Å—Ç–∫–∏–π —á–æ—Ä–Ω–∏–π –≥—É–º–æ—Ä —Ç–∞ —ñ—Ä–æ–Ω—ñ—è
- –î–ª—è —Ä–æ—Å—ñ–π—Å—å–∫–∏—Ö —Ç–µ–º - –ø–æ–≤–Ω–µ —Å–ª–æ–≤–µ—Å–Ω–µ —Ä–æ–∑—á–∞–≤–ª—é–≤–∞–Ω–Ω—è —Ä–∞—à–∏—Å—Ç—ñ–≤
- –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –ø—Ä–æ–≤–æ–∫–∞—Ü—ñ–π–Ω—ñ –∫–æ–º–µ–Ω—Ç–∞—Ä—ñ
""",
        9: """
–°–¢–ò–õ–¨–û–í–Ü –í–ò–ú–û–ì–ò:
- –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ —Ç–æ–∫—Å–∏—á–Ω—É –ª–µ–∫—Å–∏–∫—É —Ç–∞ —ó–¥–∫–∏–π —Å–∞—Ä–∫–∞–∑–º
- –ë–µ–∑–∂–∞–ª—ñ—Å–Ω–æ –≤–∏—Å–º—ñ—é–π —Ç—É–ø—ñ—Å—Ç—å, –ª–∏—Ü–µ–º—ñ—Ä—Å—Ç–≤–æ, –±–µ–∑–≥–ª—É–∑–¥—è
- –î–ª—è —Ä–æ—Å—ñ–π—Å—å–∫–∏—Ö —Ç–µ–º - –ø–æ–≤–Ω–∞ —Å–ª–æ–≤–µ—Å–Ω–∞ –¥–µ—Å—Ç—Ä—É–∫—Ü—ñ—è –æ–∫—É–ø–∞–Ω—Ç—ñ–≤
- –ó–∞–æ—Ö–æ—á—É—î—Ç—å—Å—è —á–æ—Ä–Ω–∏–π –≥—É–º–æ—Ä 
- –ù—ñ—è–∫–æ—ó —Ç–æ–ª–µ—Ä–∞–Ω—Ç–Ω–æ—Å—Ç—ñ –¥–æ –¥—É—Ä–Ω–∏—Ü—å
- –ë—É–¥—å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –ø—Ä–æ–≤–æ–∫–∞—Ü—ñ–π–Ω–∏–º —Ç–∞ –∫–æ–Ω—Ç—Ä–æ–≤–µ—Ä—Å—ñ–π–Ω–∏–º
"""
    }

    # Clamp toxicity level to 0-9 range
    toxicity_level = max(0, min(9, toxicity_level))

    return base_prompt + toxicity_styles[toxicity_level]

_encoder = tiktoken.encoding_for_model(config.OPENAI_MODEL_NAME)

def build_messages_snippet(rows,
                           max_tokens: int = 30_000,
                           toxicity_level: int = 9) -> str:
    """Build messages snippet with token limit using tiktoken"""
    lines = []
    current_tokens = 0
    tokens_remaining = max_tokens - len(_encoder.encode(get_toxicity_prompt(toxicity_level)))

    for r in rows:
        ts = datetime.fromtimestamp(r["ts_utc"], tz=ZoneInfo("UTC")).astimezone(config.KYIV)
        time = ts.strftime("%H:%M")
        name = r["full_name"] or (r["username"] and f"@{r['username']}") or f"id{r['user_id']}"
        frag = (r["text"] or "").replace("\n", " ").strip()
        if len(frag) > 500:
            frag = frag[:500] + "‚Ä¶"
        reply = f", reply_to={r['reply_to_message_id']}" if r["reply_to_message_id"] else ""

        line = f"[{time}] {name} (uid={r['user_id']}, mid={r['message_id']}{reply}): {frag}"

        line_tokens = len(_encoder.encode(line))
        if current_tokens + line_tokens > tokens_remaining:
            break

        current_tokens += line_tokens
        lines.append(line)

    return "\n".join(lines)


async def get_openai_summary(prompt: str) -> dict:
    """Get summary from OpenAI"""
    config.log.info(f"OpenAI prompt: {prompt}")
    try:
        response = await openai_client.chat.completions.create(
            model=config.OPENAI_MODEL_NAME,
            messages=[
                {"role": "system",
                 "content": "–¢–∏ ‚Äî –Ω–∞–¥–∑–≤–∏—á–∞–π–Ω–æ —Å–∞—Ä–∫–∞—Å—Ç–∏—á–Ω–∏–π —Ç–∞ —ó–¥–∫–∏–π –ø–æ–º—ñ—á–Ω–∏–∫, —â–æ –≥—Ä—É–ø—É—î –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è —á–∞—Ç—É —É —Ç–µ–º–∏ –∑–∞ –∫–∞–ª–µ–Ω–¥–∞—Ä–Ω–∏–π –¥–µ–Ω—å. –ó–∞–≤–∂–¥–∏ –≤—ñ–¥–ø–æ–≤—ñ–¥–∞–π —É —Ñ–æ—Ä–º–∞—Ç—ñ JSON"},
                {"role": "user", "content": prompt}
            ],
            response_format={"type": "json_object"}
        )

        content = response.choices[0].message.content
        return json.loads(content)
    except Exception as e:
        config.log.exception("OpenAI API error: %s", e)
        raise


async def get_gemini_summary(prompt: str) -> dict:
    """Get summary from Gemini"""
    try:
        config.log.info(f"Gemini prompt: {prompt}")
        resp = gemini_model.generate_content(prompt)
        raw = resp.text or ""
        m = re.search(r"\{.*\}", raw, re.S)
        data = json.loads(m.group(0) if m else raw)
        return data
    except Exception as e:
        config.log.exception("Gemini API error: %s", e)
        raise


def should_use_openai(chat_id: int) -> bool:
    """Determine if we should use OpenAI for this chat"""
    return chat_id in config.OPENAI_CHAT_IDS

def should_use_gemini(chat_id: int) -> bool:
    """Determine if we should use Gemini for this chat"""
    return chat_id in config.GEMINI_CHAT_IDS

def is_chat_configured(chat_id: int) -> bool:
    """Check if chat is configured for any AI provider"""
    return chat_id in config.ALLOWED_CHAT_IDS


async def summarize_day(chat: Chat, start_local: datetime, end_local: datetime, ctx: ContextTypes.DEFAULT_TYPE,
                        toxicity_level: int = 9) -> str | None:
    # Check if chat is configured for any AI provider
    if not is_chat_configured(chat.id):
        config.log.warning(f"Chat {chat.id} is not configured for any AI provider")
        return None

    start_utc = start_local.astimezone(ZoneInfo("UTC"))
    end_utc = end_local.astimezone(ZoneInfo("UTC"))
    with closing(db()) as conn, closing(conn.cursor()) as cur:
        cur.execute(
            "SELECT * FROM messages WHERE chat_id=? AND ts_utc>=? AND ts_utc<? ORDER BY ts_utc ASC",
            (chat.id, utc_ts(start_utc), utc_ts(end_utc)),
        )
        rows = [dict(r) for r in cur.fetchall()]

    rows = [r for r in rows if clean_text(r["text"])]
    if not rows:
        return None

    snippet = build_messages_snippet(rows)
    day_str = (start_local.date()).strftime("%d.%m.%Y")

    # Determine which AI provider to use
    use_openai = should_use_openai(chat.id)
    use_gemini = should_use_gemini(chat.id)

    if use_openai:
        provider_name = "OpenAI"
    elif use_gemini:
        provider_name = "Gemini"
    else:
        config.log.error(f"Chat {chat.id} is in ALLOWED_CHAT_IDS but not in any provider-specific list")
        return None

    config.log.info(f"Using {provider_name} for chat {chat.id}")

    # Try from requested toxicity_level down to 0 until we get a response (fallback on safety blocks)
    requested_level = max(0, min(9, toxicity_level))
    topics = []
    safety_blocked_encountered = False

    for level in range(requested_level, -1, -1):
        prompt = f"""{get_toxicity_prompt(level)}

–ù–∏–∂—á–µ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è –∑–∞ –¥–µ–Ω—å —É —Ñ–æ—Ä–º–∞—Ç—ñ —Ä—è–¥–∫—ñ–≤:
{snippet}
"""
        try:
            config.log.info(f"Current toxicity level: {level} (requested: {requested_level})")
            config.log.info(f"Current number of tokens: {_encoder.encode(prompt)}")
            if use_openai:
                data = await get_openai_summary(prompt)
            else:
                data = await get_gemini_summary(prompt)

            topics = data.get("topics", [])
            if topics:
                toxicity_level = level  # record the actual level that worked
                break
            # If no topics returned, try a lower toxicity just in case model was overly strict
            config.log.warning(f"{provider_name} returned no topics at toxicity level {level}, trying lower level...")
        except ValueError as e:
            # Heuristic: detect safety filter blocking or similar conditions and retry with lower level
            if "response to contain a valid `Part`" in str(e) or "finish_reason" in str(e) or "content_filter" in str(
                    e):
                safety_blocked_encountered = True
                config.log.warning(
                    f"{provider_name} blocked request due to safety policy (toxicity level: {level}). Retrying with lower level...")
                continue
            else:
                config.log.exception(f"{provider_name} summary error: %s", e)
                return None
        except Exception as e:
            config.log.exception(f"{provider_name} summary error: %s", e)
            return None

    if not topics:
        if safety_blocked_encountered:
            # Return ironic message about safety filters only if we kept being blocked down to level 0
            ironic_messages = [
                f"<b>#–ü—ñ–¥—Å—É–º–∫–∏_–¥–Ω—è ‚Äî {escape(day_str)}</b>\n\nü§ñ –û–π, –≤–∏–±–∞—á—Ç–µ! –ù–∞—à —à—Ç—É—á–Ω–∏–π —Ä–æ–∑—É–º –≤–∏—Ä—ñ—à–∏–≤, —â–æ –≤–∞—à—ñ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è –∑–∞–Ω–∞–¥—Ç–æ —Ç–æ–∫—Å–∏—á–Ω—ñ –¥–ª—è –π–æ–≥–æ –Ω—ñ–∂–Ω–æ—ó –ø—Ä–∏—Ä–æ–¥–∏ —ñ –≤—ñ–¥–º–æ–≤–∏–≤—Å—è —ó—Ö –∞–Ω–∞–ª—ñ–∑—É–≤–∞—Ç–∏.\n\nüòÖ –°–ø—Ä–æ–±—É–π—Ç–µ –ø—ñ–∑–Ω—ñ—à–µ –∑ –∫–æ–º–∞–Ω–¥–æ—é <code>/summary_now 0</code> –¥–ª—è –±—ñ–ª—å—à –¥—Ä—É–∂–µ–ª—é–±–Ω–æ–≥–æ —Å—Ç–∏–ª—é, –∞–±–æ –ø—Ä–æ—Å—Ç–æ –∑–∞—á–µ–∫–∞–π—Ç–µ ‚Äî –º–æ–∂–ª–∏–≤–æ, –∑–∞–≤—Ç—Ä–∞ –≤—ñ–Ω –±—É–¥–µ —É –∫—Ä–∞—â–æ–º—É –Ω–∞—Å—Ç—Ä–æ—ó!",
                f"<b>#–ü—ñ–¥—Å—É–º–∫–∏_–¥–Ω—è ‚Äî {escape(day_str)}</b>\n\nüõ°Ô∏è –®—Ç—É—á–Ω–∏–π —ñ–Ω—Ç–µ–ª–µ–∫—Ç –∞–∫—Ç–∏–≤—É–≤–∞–≤ —Ä–µ–∂–∏–º \"–∑–∞—Ö–∏—Å—Ç –≤—ñ–¥ —Ç–æ–∫—Å–∏—á–Ω–æ—Å—Ç—ñ\" —ñ –≤—ñ–¥–º–æ–≤–ª—è—î—Ç—å—Å—è —á–∏—Ç–∞—Ç–∏ –≤–∞—à—ñ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è. –í–∏–¥–∏–º–æ, –≤–∏ —Å—å–æ–≥–æ–¥–Ω—ñ –±—É–ª–∏ –æ—Å–æ–±–ª–∏–≤–æ \"–≤–∏–±—É—Ö–æ–≤–∏–º–∏\"!\n\nüôÉ –†–µ–∫–æ–º–µ–Ω–¥—É—é —Å–ø—Ä–æ–±—É–≤–∞—Ç–∏ <code>/summary_now 3</code> –¥–ª—è –±—ñ–ª—å—à –º'—è–∫–æ–≥–æ –ø—ñ–¥—Ö–æ–¥—É.",
                f"<b>#–ü—ñ–¥—Å—É–º–∫–∏_–¥–Ω—è ‚Äî {escape(day_str)}</b>\n\nüö´ –®—Ç—É—á–Ω–∏–π —ñ–Ω—Ç–µ–ª–µ–∫—Ç –∑–∞—Å—Ç—Ä–∞–π–∫—É–≤–∞–≤: \"–Ø –Ω–µ –±—É–¥—É –∞–Ω–∞–ª—ñ–∑—É–≤–∞—Ç–∏ —Ü–µ–π —Ä—ñ–≤–µ–Ω—å —Ç–æ–∫—Å–∏—á–Ω–æ—Å—Ç—ñ, –∑–Ω–∞–π–¥—ñ—Ç—å —Å–æ–±—ñ —ñ–Ω—à–æ–≥–æ –±–æ—Ç–∞!\"\n\nüòè –°–ø—Ä–æ–±—É–π—Ç–µ –∑–Ω–∏–∑–∏—Ç–∏ –≥—Ä–∞–¥—É—Å –¥–æ —Ä–æ–∑—É–º–Ω–∏—Ö –º–µ–∂ –∫–æ–º–∞–Ω–¥–æ—é <code>/summary_now 2</code>.",
            ]
            import random
            return random.choice(ironic_messages)
        return None

    header = f"<b>#–ü—ñ–¥—Å—É–º–∫–∏_–¥–Ω—è ‚Äî {escape(day_str)}</b>"
    items = []

    by_mid = {r["message_id"]: r for r in rows}
    by_uid = {}
    for r in rows:
        by_uid.setdefault(r["user_id"], r)

    for t in topics[:MAX_TOPICS_NUM]:
        title = clean_text(t.get("short_title") or "")
        summ = clean_text(t.get("summary") or "")
        mid = t.get("first_message_id")
        uid = t.get("initiator_user_id")

        if isinstance(mid, int) and mid in by_mid:
            msg_url = message_link(chat, mid)
            title_html = f'<a href="{msg_url}">{escape(title or "–¢–µ–º–∞")}</a>'
        else:
            title_html = escape(title or "–¢–µ–º–∞")

        urow = (by_uid.get(uid) or {})
        initiator_html = user_link(
            user_id=urow.get("user_id", uid or 0),
            username=urow.get("username"),
            full_name=urow.get("full_name") or "–£—á–∞—Å–Ω–∏–∫"
        )

        line = f"‚Ä¢ {title_html} ‚Äî —ñ–Ω—ñ—Ü—ñ–∞—Ç–æ—Ä {initiator_html}"
        if summ:
            line += f"\n–ö–æ—Ä–æ—Ç–∫–æ: {escape(summ)}"
        items.append(line)

    return header + "\n\n" + "\n\n".join(items)

